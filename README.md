# ğŸš—â›½ Pipeline ETL - AnÃ¡lise de PreÃ§os de CombustÃ­veis no Brasil

## ğŸ“Š Sobre o Projeto
Este projeto implementa um pipeline ETL (Extract, Transform, Load) para anÃ¡lise avanÃ§ada de preÃ§os de combustÃ­veis no Brasil, utilizando dados histÃ³ricos do Kaggle (2004-2021). O projeto emprega tecnologias de Big Data como **Apache Spark** e conceitos de **Data Lake** para processar e analisar grandes volumes de dados de forma eficiente.

### ğŸ¯ Objetivo
Construir um sistema robusto de anÃ¡lise de dados que permite:
- ExtraÃ§Ã£o automatizada de dados do Kaggle
- TransformaÃ§Ã£o dos dados em um modelo dimensional (Star Schema)
- AnÃ¡lises avanÃ§adas com Spark SQL para responder questÃµes de negÃ³cio
- Consultas otimizadas para grandes volumes de dados

### ğŸ—ï¸ Arquitetura
O projeto utiliza uma arquitetura de **Data Lake** com trÃªs camadas:
- **Bronze** (Raw Data): Dados brutos extraÃ­dos do Kaggle
- **Silver** (Curated Data): Dados limpos e transformados em modelo dimensional
- **Gold** (Business Data): Dados agregados e otimizados para anÃ¡lises especÃ­ficas

## ğŸ› ï¸ Tecnologias Utilizadas

### Core Technologies
- **Apache Spark 3.5+**: Motor de processamento distribuÃ­do para transformaÃ§Ãµes e anÃ¡lises
- **Python 3.11+**: Linguagem principal do projeto
- **PyArrow**: Interface para formatos de dados colunares
- **Parquet**: Formato de armazenamento colunar otimizado

### Data Engineering Stack
- **Kaggle API**: ExtraÃ§Ã£o automatizada de dados
- **Data Lake Architecture**: OrganizaÃ§Ã£o em camadas Bronze/Silver/Gold
- **Star Schema**: Modelagem dimensional para anÃ¡lises OLAP
- **Spark SQL**: Engine de consultas para anÃ¡lises complexas

### Infrastructure & Tools
- **pytest**: Framework de testes
- **logging**: Sistema de logs estruturado
- **pathlib**: Gerenciamento de caminhos de arquivos
- **typing**: Type hints para melhor qualidade de cÃ³digo

## ğŸ“‹ PrÃ©-requisitos

- Python 3.11 ou superior
- pip (gerenciador de pacotes Python)
- Conta no Kaggle (para acesso aos dados)
- Git

## ğŸš€ ConfiguraÃ§Ã£o do Ambiente

1. **Clone o repositÃ³rio**:
```cmd
git clone https://github.com/WillianOliveir1/BD3-2025.1.git
cd BD3-2025.1
```

2. **Crie e ative um ambiente virtual**:
```cmd
python -m venv venv
venv\Scripts\activate
```

3. **Instale as dependÃªncias**:
```cmd
pip install -r requirements.txt
```

4. **Configure as credenciais do Kaggle**:
   - Acesse [kaggle.com](https://www.kaggle.com/)
   - VÃ¡ em "Account" > "API" > "Create New API Token"
   - O navegador irÃ¡ baixar automaticamente o arquivo `kaggle.json`
   - Crie a pasta `.kaggle` no seu diretÃ³rio home, se ela nÃ£o existir:
     ```cmd
     mkdir %USERPROFILE%\.kaggle
     ```
   - Mova o arquivo `kaggle.json` baixado para a pasta `.kaggle`:
     ```cmd
     move %USERPROFILE%\Downloads\kaggle.json %USERPROFILE%\.kaggle\
     ```
   - **âš ï¸ Importante**: 
     - Nunca compartilhe o arquivo `kaggle.json` ou adicione-o ao controle de versÃ£o
     - O arquivo deve ficar apenas em `%USERPROFILE%\.kaggle\kaggle.json`

## âš™ï¸ ConfiguraÃ§Ã£o das VariÃ¡veis de Ambiente

O projeto utiliza um arquivo `.env` para configurar variÃ¡veis de ambiente importantes. 

### ğŸ”¥ SPARK_HOME
- **O que Ã©**: Caminho para a instalaÃ§Ã£o do Apache Spark
- **Como configurar**: 
  1. Baixe o Apache Spark da [pÃ¡gina oficial](https://spark.apache.org/downloads.html)
  2. Descompacte em um diretÃ³rio (ex: `C:\spark-3.5.0-bin-hadoop3`)
  3. Defina `SPARK_HOME` com o caminho completo para este diretÃ³rio

### ğŸ”‘ KAGGLE_USERNAME e KAGGLE_KEY
- **O que Ã©**: Suas credenciais do Kaggle
- **Como configurar**:
  1. Acesse [kaggle.com/account](https://www.kaggle.com/account)
  2. Role atÃ© a seÃ§Ã£o "API"
  3. Clique em "Create New API Token"
  4. Abra o arquivo `kaggle.json` baixado
  5. Copie o valor de "username" para `KAGGLE_USERNAME`
  6. Copie o valor de "key" para `KAGGLE_KEY`

### â˜• JAVA_HOME
- **O que Ã©**: Caminho para a instalaÃ§Ã£o do Java JDK
- **Como configurar**:
  1. Instale o Java JDK 11 ou superior
  2. Encontre o diretÃ³rio de instalaÃ§Ã£o (geralmente em `C:\Program Files\Java\jdk-11.x.x`)
  3. Defina `JAVA_HOME` com o caminho completo para este diretÃ³rio

### ğŸ“‚ DATA_PATH
- **O que Ã©**: Caminho para o diretÃ³rio onde os dados serÃ£o armazenados
- **Valor padrÃ£o**: `./data`
- **Como configurar**: 
  - Mantenha o valor padrÃ£o `./data` para usar o diretÃ³rio local
  - Ou defina um caminho absoluto para armazenar os dados em outro local

### ğŸ“Š KAGGLE_DATASET
- **O que Ã©**: Identificador do dataset do Kaggle que serÃ¡ usado
- **Valor padrÃ£o**: `matheusfreitag/gas-prices-in-brazil`
- **ObservaÃ§Ã£o**: NÃ£o altere este valor, ele Ã© especÃ­fico para este projeto

## ğŸ“ Estrutura do Projeto

O projeto segue uma arquitetura de **Data Lake** moderna com separaÃ§Ã£o clara de responsabilidades:

```
ğŸ“¦ BD3-2025.1/
â”œâ”€â”€ ğŸ“‚ data/                           # ğŸ—ï¸ Data Lake - Armazenamento em Camadas
â”‚   â”œâ”€â”€ ğŸ¥‰ bronze/                     # Dados brutos (Raw Data)
â”‚   â”‚   â””â”€â”€ kaggle/
â”‚   â”‚       â””â”€â”€ gas_prices_in_brazil/
â”‚   â”‚           â”œâ”€â”€ YYYYMMDD/
â”‚   â”‚               â””â”€â”€ 2004-2021.tsv
â”‚   â”‚           
â”‚   â”œâ”€â”€ ğŸ¥ˆ silver/                     # Dados curados (Star Schema)
â”‚   â”‚   â””â”€â”€ kaggle/
â”‚   â”‚       â””â”€â”€ gas_prices_in_brazil/
â”‚   â”‚           â”œâ”€â”€ dim_estado.parquet/     # DimensÃ£o Estados
â”‚   â”‚           â”œâ”€â”€ dim_produto.parquet/    # DimensÃ£o Produtos
â”‚   â”‚           â”œâ”€â”€ dim_regiao.parquet/     # DimensÃ£o RegiÃµes
â”‚   â”‚           â”œâ”€â”€ dim_tempo.parquet/      # DimensÃ£o Tempo
â”‚   â”‚           â””â”€â”€ fact_precos.parquet/    # Tabela Fato - PreÃ§os
â”‚   â””â”€â”€ ğŸ¥‡ gold/                       # Dados para negÃ³cio (Analytics Ready)
â”œâ”€â”€ ğŸ“‚ src/                            # ğŸ’» CÃ³digo Fonte
â”‚   â”œâ”€â”€ ğŸ“‚ analysis/                   # ğŸ“Š MÃ³dulos de AnÃ¡lise
â”‚   â”‚   â”œâ”€â”€ fuel_price_analyzer.py     # Analisador principal
â”‚   â”‚   â””â”€â”€ run_analysis.py            # Runner de anÃ¡lises
â”‚   â”œâ”€â”€ ğŸ“‚ infrastructure/             # ğŸ—ï¸ Infraestrutura e ConfiguraÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ config.py                  # ConfiguraÃ§Ãµes globais
â”‚   â”‚   â”œâ”€â”€ data_lake_manager.py       # Gerenciador do Data Lake
â”‚   â”‚   â”œâ”€â”€ environment_manager.py     # Gerenciador de ambiente
â”‚   â”‚   â”œâ”€â”€ hadoop_setup.py            # ConfiguraÃ§Ã£o Hadoop
â”‚   â”‚   â”œâ”€â”€ logging_config.py          # Sistema de logs
â”‚   â”‚   â””â”€â”€ spark_manager.py           # Gerenciador Spark
â”‚   â””â”€â”€ ğŸ“‚ pipeline/                   # ğŸ”„ Pipeline ETL
â”‚       â””â”€â”€ kaggle/                    # Pipeline especÃ­fico Kaggle
â”‚           â”œâ”€â”€ upstream/              # â¬‡ï¸ ExtraÃ§Ã£o (Extract)
â”‚           â”‚   â””â”€â”€ extractor.py
â”‚           â”œâ”€â”€ midstream/             # ğŸ”„ TransformaÃ§Ã£o (Transform)
â”‚           â”‚   â””â”€â”€ transformer.py
â”‚           â”œâ”€â”€ downstream/            # â¬†ï¸ Carregamento (Load)
â”‚           â”‚   â””â”€â”€ loader.py
â”‚           â”œâ”€â”€ etl_pipeline.py        # ğŸš€ Pipeline principal
â”‚           â””â”€â”€ run_pipeline.py        # Runner do pipeline
â”œâ”€â”€ ğŸ“‚ tests/                          # ğŸ§ª Testes Automatizados
â”œâ”€â”€ ğŸ“„ requirements.txt                # ğŸ“¦ DependÃªncias Python
â”œâ”€â”€ ğŸ“„ setup.py                        # âš™ï¸ ConfiguraÃ§Ã£o do projeto
â””â”€â”€ ğŸ“– README.md                       # DocumentaÃ§Ã£o
```

### ğŸ—ï¸ Arquitetura em Camadas

#### ğŸ¥‰ Bronze Layer (Raw Data)
- **PropÃ³sito**: Armazenamento de dados brutos extraÃ­dos do Kaggle
- **Formato**: TSV (Tab-Separated Values)
- **OrganizaÃ§Ã£o**: Particionado por data de extraÃ§Ã£o
- **CaracterÃ­sticas**: Dados imutÃ¡veis, backup histÃ³rico

#### ğŸ¥ˆ Silver Layer (Curated Data)
- **PropÃ³sito**: Dados limpos e transformados em modelo dimensional
- **Formato**: Parquet (otimizado para consultas analÃ­ticas)
- **Modelo**: Star Schema com dimensÃµes e tabela fato
- **CaracterÃ­sticas**: Dados validados, tipados e otimizados

#### ğŸ¥‡ Gold Layer (Business Data)
- **PropÃ³sito**: Dados agregados e otimizados para casos de uso especÃ­ficos
- **Formato**: Parquet com particionamento estratÃ©gico
- **CaracterÃ­sticas**: Dados prontos para visualizaÃ§Ã£o e relatÃ³rios

## ğŸ—„ï¸ Modelo de Dados - Star Schema

### ğŸ“Š Arquitetura Dimensional

O projeto implementa um **Star Schema** otimizado para anÃ¡lises OLAP (Online Analytical Processing):

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   dim_tempo     â”‚
                    â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
                    â”‚ id (PK)         â”‚
                    â”‚ inicio          â”‚
                    â”‚ fim             â”‚
                    â”‚ semana          â”‚
                    â”‚ mes             â”‚
                    â”‚ ano             â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  dim_produto    â”‚â”‚â”‚   dim_regiao    â”‚
            â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚â”‚â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
            â”‚ id (PK)         â”‚â”‚â”‚ id (PK)         â”‚
            â”‚ nome            â”‚â”‚â”‚ nome            â”‚
            â”‚ unidade         â”‚â”‚â”‚ codigo          â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚        â”‚          â”‚
                      â”‚    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”
                      â”‚    â”‚   fact_precos    â”‚
                      â”‚    â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
                      â””â”€â”€â”€â”€â”¤ produtoId (FK)   â”‚
                           â”‚ estadoId (FK)    â”‚
                           â”‚ regiaoId (FK)    â”‚
                           â”‚ tempoId (FK)     â”‚
                           â”‚ pMed             â”‚
                           â”‚ pMin             â”‚
                           â”‚ pMax             â”‚
                           â”‚ desvio           â”‚
                           â”‚ coef_var         â”‚
                           â”‚ registro_count   â”‚
                           â””â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   dim_estado    â”‚
                    â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
                    â”‚ id (PK)         â”‚
                    â”‚ sigla           â”‚
                    â”‚ nome            â”‚
                    â”‚ regiaoId (FK)   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“‹ DescriÃ§Ã£o das Tabelas

#### ğŸ¯ **fact_precos** (Tabela Fato)
- **PropÃ³sito**: Armazena os preÃ§os dos combustÃ­veis com mÃ©tricas agregadas
- **Granularidade**: Por produto, estado, regiÃ£o e perÃ­odo
- **MÃ©tricas**:
  - `pMed`: PreÃ§o mÃ©dio de revenda
  - `pMin`: PreÃ§o mÃ­nimo de revenda  
  - `pMax`: PreÃ§o mÃ¡ximo de revenda
  - `desvio`: Desvio padrÃ£o dos preÃ§os
  - `coef_var`: Coeficiente de variaÃ§Ã£o
  - `registro_count`: Quantidade de registros agregados

#### ğŸ·ï¸ **dim_produto** (DimensÃ£o Produto)
- **PropÃ³sito**: Tipos de combustÃ­veis disponÃ­veis
- **Exemplos**: Gasolina Comum, Etanol Hidratado, Diesel S-10, GNV

#### ğŸŒ **dim_regiao** (DimensÃ£o RegiÃ£o)
- **PropÃ³sito**: RegiÃµes geogrÃ¡ficas do Brasil
- **Valores**: Norte, Nordeste, Centro-Oeste, Sudeste, Sul

#### ğŸ›ï¸ **dim_estado** (DimensÃ£o Estado)
- **PropÃ³sito**: Estados brasileiros com relacionamento hierÃ¡rquico
- **CaracterÃ­sticas**: Vinculado Ã  regiÃ£o correspondente

#### ğŸ“… **dim_tempo** (DimensÃ£o Tempo)
- **PropÃ³sito**: PerÃ­odos de anÃ¡lise com hierarquia temporal
- **Granularidade**: PerÃ­odos semanais com componentes de data
- **Componentes**: Ano, mÃªs, semana para drill-down/roll-up

## ğŸš€ ExecuÃ§Ã£o do Pipeline

### ğŸ”„ Pipeline Completo (Recomendado)
Execute todo o processo ETL de uma vez:
```cmd
python src/pipeline/kaggle/run_pipeline.py
```

### âš™ï¸ ExecuÃ§Ã£o por Etapas
Para desenvolvimento e debugging, execute etapas especÃ­ficas:

```cmd
# 1ï¸âƒ£ ExtraÃ§Ã£o (Bronze) - Dados do Kaggle
python src/pipeline/kaggle/run_stages.py --stage extract

# 2ï¸âƒ£ TransformaÃ§Ã£o (Silver) - Modelo Dimensional
python src/pipeline/kaggle/run_stages.py --stage transform

# 3ï¸âƒ£ Carregamento (Gold) - Dados Agregados
python src/pipeline/kaggle/run_stages.py --stage load
```

### ğŸ“Š Executar AnÃ¡lises
Execute anÃ¡lises especÃ­ficas sobre os dados processados:
```cmd
python src/analysis/run_analysis.py
```

## ğŸ§ª Testes e ValidaÃ§Ã£o

### ğŸƒâ€â™‚ï¸ Executar Todos os Testes
```cmd
python -m pytest tests/ -v
```

### ğŸ¯ Executar Testes EspecÃ­ficos
```cmd
# Teste de extraÃ§Ã£o de dados
python -m pytest tests/test_extract.py -v

# Teste do pipeline ETL
python -m pytest tests/test_etl_pipeline.py -v

# Teste do gerenciador Spark
python -m pytest tests/test_spark_manager.py -v

# Teste de transformaÃ§Ãµes
python -m pytest tests/test_transform.py -v
```

### ğŸ“ˆ Cobertura de Testes
```cmd
python -m pytest tests/ --cov=src --cov-report=html
```

## ğŸ“Š Estrutura dos Dados e Fonte

### ğŸ¥‰ Camada Bronze
- **Dataset**: `gas_prices_in_brazil`
- **Arquivo**: `2004-2021.tsv` (125MB+)
- **Fonte**: [Kaggle - Gas Prices in Brazil](https://www.kaggle.com/matheusfreitag/gas-prices-in-brazil)
- **PerÃ­odo**: 2004-2021 (18 anos de dados histÃ³ricos)
- **Registros**: ~2.8 milhÃµes de registros
- **AtualizaÃ§Ã£o**: Particionado por data de extraÃ§Ã£o para versionamento

### ğŸ” DicionÃ¡rio de Dados
### ğŸ—‚ï¸ Dados Origem (Kaggle)
- **Arquivo**: `2004-2021.tsv`
- **Formato**: Tab-Separated Values (TSV)

| Campo | Tipo | DescriÃ§Ã£o |
|-------|------|-----------|
| `DATA INICIAL` | Date | Data de inÃ­cio da coleta |
| `DATA FINAL` | Date | Data final da coleta |
| `REGIÃƒO` | String | RegiÃ£o geogrÃ¡fica (N, NE, CO, SE, S) |
| `ESTADO` | String | Estado brasileiro (sigla) |
| `PRODUTO` | String | Tipo de combustÃ­vel |
| `NÃšMERO DE POSTOS PESQUISADOS` | Integer | Quantidade de postos na amostra |
| `UNIDADE DE MEDIDA` | String | Medida do produto (R$/l, R$/mÂ³) |
| `PREÃ‡O MÃ‰DIO REVENDA` | Double | MÃ©dia dos preÃ§os coletados |
| `DESVIO PADRÃƒO REVENDA` | Double | Desvio padrÃ£o dos preÃ§os |
| `PREÃ‡O MÃNIMO REVENDA` | Double | Menor preÃ§o encontrado |
| `PREÃ‡O MÃXIMO REVENDA` | Double | Maior preÃ§o encontrado |
| `COEF DE VARIAÃ‡ÃƒO REVENDA` | Double | Coeficiente de variaÃ§Ã£o dos preÃ§os |

#### ğŸ“Š Tabela Fato (fact_precos)
| Campo | Tipo | DescriÃ§Ã£o |
|-------|------|-----------|
| `produtoId` | Long | ID do produto (FK) |
| `estadoId` | Long | ID do estado (FK) |
| `regiaoId` | Long | ID da regiÃ£o (FK) |
| `tempoId` | Long | ID do perÃ­odo (FK) |
| `pMed` | Double | PreÃ§o mÃ©dio de revenda (R$) |
| `pMin` | Double | PreÃ§o mÃ­nimo de revenda (R$) |
| `pMax` | Double | PreÃ§o mÃ¡ximo de revenda (R$) |
| `desvio` | Double | Desvio padrÃ£o dos preÃ§os |
| `coef_var` | Double | Coeficiente de variaÃ§Ã£o |
| `registro_count` | Long | Quantidade de registros agregados |

#### ğŸ·ï¸ DimensÃ£o Produto (dim_produto)
| Campo | Tipo | DescriÃ§Ã£o |
|-------|------|-----------|
| `id` | Long | ID Ãºnico do produto (PK) |
| `nome` | String | Nome do combustÃ­vel |
| `unidade` | String | Unidade de medida |

#### ğŸŒ DimensÃ£o RegiÃ£o (dim_regiao)
| Campo | Tipo | DescriÃ§Ã£o |
|-------|------|-----------|
| `id` | Long | ID Ãºnico da regiÃ£o (PK) |
| `nome` | String | Nome da regiÃ£o |
| `codigo` | String | Sigla da regiÃ£o |

#### ğŸ›ï¸ DimensÃ£o Estado (dim_estado)
| Campo | Tipo | DescriÃ§Ã£o |
|-------|------|-----------|
| `id` | Long | ID Ãºnico do estado (PK) |
| `sigla` | String | Sigla do estado |
| `nome` | String | Nome do estado |
| `regiaoId` | Long | ID da regiÃ£o (FK) |

#### ğŸ“… DimensÃ£o Tempo (dim_tempo)
| Campo | Tipo | DescriÃ§Ã£o |
|-------|------|-----------|
| `id` | Long | ID Ãºnico do perÃ­odo (PK) |
| `inicio` | Date | Data de inÃ­cio |
| `fim` | Date | Data de fim |
| `semana` | Int | NÃºmero da semana |
| `mes` | Int | NÃºmero do mÃªs |
| `ano` | Int | Ano |

## ğŸ’¡ Funcionalidades Implementadas

### ğŸ”§ Pipeline ETL Robusto
- âœ… ExtraÃ§Ã£o automatizada com retry e validaÃ§Ã£o
- âœ… TransformaÃ§Ãµes usando Apache Spark
- âœ… Modelo dimensional com Star Schema
- âœ… Particionamento inteligente dos dados
- âœ… Sistema de logs estruturado
- âœ… Testes automatizados

### ğŸ“ˆ AnÃ¡lises AvanÃ§adas
- âœ… Consultas Spark SQL otimizadas
- âœ… AgregaÃ§Ãµes por mÃºltiplas dimensÃµes
- âœ… AnÃ¡lise temporal com drill-down
- âœ… ComparaÃ§Ãµes regionais e por produto
- âœ… MÃ©tricas estatÃ­sticas (mÃ©dia, min, max, desvio)

### ğŸ—ï¸ Infraestrutura Moderna
- âœ… ConfiguraÃ§Ã£o automÃ¡tica do ambiente Spark
- âœ… Gerenciamento de Data Lake
- âœ… Suporte a Hadoop (opcional)
- âœ… Arquitetura escalÃ¡vel e modular

## ğŸ¯ Casos de Uso de AnÃ¡lise

Este projeto permite responder questÃµes como:

### ğŸ“Š AnÃ¡lises de PreÃ§o
- Maiores e menores preÃ§os por combustÃ­vel/regiÃ£o/perÃ­odo
- EvoluÃ§Ã£o temporal dos preÃ§os
- ComparaÃ§Ã£o entre estados e regiÃµes
- Volatilidade dos preÃ§os (coeficiente de variaÃ§Ã£o)

### â›½ AnÃ¡lises Comparativas
- CombustÃ­vel mais econÃ´mico por regiÃ£o/perÃ­odo
- AnÃ¡lise de competitividade Etanol vs Gasolina
- Ranking de estados por preÃ§o mÃ©dio
- Sazonalidade dos preÃ§os

### ğŸ­ AnÃ¡lises de Mercado
- ParticipaÃ§Ã£o por tipo de combustÃ­vel
- ConcentraÃ§Ã£o regional de preÃ§os
- AnÃ¡lise de outliers e anomalias
- TendÃªncias de longo prazo

## ğŸ¤ Contribuindo

1. **Crie um branch para sua feature**:
```cmd
git checkout -b feature/nova-funcionalidade
```

2. **FaÃ§a suas alteraÃ§Ãµes e commit**:
```cmd
git add .
git commit -m "feat: descriÃ§Ã£o da sua funcionalidade"
```

3. **Execute os testes**:
```cmd
python -m pytest tests/ -v
```

4. **Push para o repositÃ³rio**:
```cmd
git push origin feature/nova-funcionalidade
```

5. **Abra um Pull Request**

## ğŸ“š DocumentaÃ§Ã£o Adicional

### ğŸ”— Links Ãšteis
- [Apache Spark Documentation](https://spark.apache.org/docs/latest/)
- [Kaggle API Documentation](https://github.com/Kaggle/kaggle-api)
- [PyArrow Documentation](https://arrow.apache.org/docs/python/)
- [Dataset Original](https://www.kaggle.com/datasets/matheusfreitag/gas-prices-in-brazil)

### ğŸ† Melhores PrÃ¡ticas Implementadas
- **Arquitetura em Camadas**: SeparaÃ§Ã£o clara Bronze/Silver/Gold
- **Modelo Dimensional**: Star Schema para consultas eficientes
- **Formato Colunar**: Parquet para performance analÃ­tica
- **Particionamento**: OrganizaÃ§Ã£o otimizada dos dados
- **Testes Automatizados**: Garantia de qualidade
- **Logs Estruturados**: Monitoramento e debugging
- **Type Hints**: CÃ³digo mais legÃ­vel e manutenÃ­vel

## ğŸš€ PrÃ³ximos Passos

### ğŸ“ˆ Melhorias Planejadas
- [ ] ImplementaÃ§Ã£o de Hadoop distribuÃ­do
- [ ] Dashboard interativo com visualizaÃ§Ãµes
- [ ] API REST para consultas
- [ ] Pipeline CI/CD automatizado
- [ ] Monitoramento com mÃ©tricas
- [ ] Algoritmos de Machine Learning para previsÃ£o de preÃ§os

### ğŸ¯ ExtensÃµes PossÃ­veis
- [ ] IntegraÃ§Ã£o com outras fontes de dados (ANP, IBGE)
- [ ] AnÃ¡lises de correlaÃ§Ã£o com indicadores econÃ´micos
- [ ] ImplementaÃ§Ã£o de Data Quality checks
- [ ] Streaming de dados em tempo real
- [ ] Deploy em cloud (AWS, Azure, GCP)

---

## ğŸ“ LicenÃ§a

Este projeto Ã© desenvolvido para fins educacionais como parte do curso de Banco de Dados 3 (BD3-2025.1).

## ğŸ‘¥ Autores

- **Willian Oliveira** - Desenvolvimento e arquitetura

---

**â­ Se este projeto foi Ãºtil para vocÃª, considere dar uma estrela no repositÃ³rio!**
