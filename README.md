# Pipeline ETL - PreÃ§os de CombustÃ­veis no Brasil

## Sobre o Projeto
Pipeline ETL para processamento de dados histÃ³ricos de preÃ§os de combustÃ­veis no Brasil, usando dados do Kaggle para criar um modelo dimensional no formato Star Schema.


# AnÃ¡lise de PreÃ§os de CombustÃ­veis no Brasil

Este projeto implementa um pipeline ETL (Extract, Transform, Load) para anÃ¡lise de preÃ§os de combustÃ­veis no Brasil, utilizando dados do Kaggle.

## PrÃ©-requisitos

- Python 3.11 ou superior
- pip (gerenciador de pacotes Python)
- Conta no Kaggle (para acesso aos dados)
- Git

## ConfiguraÃ§Ã£o do Ambiente

1. Clone o repositÃ³rio:
```bash
git clone https://github.com/WillianOliveir1/BD3-2025.1.git
cd BD3-2025.1
```

2. Crie e ative um ambiente virtual:
```bash
python -m venv venv
.\venv\Scripts\activate
```

3. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

4. Configure as credenciais do Kaggle:
   - Acesse [kaggle.com](https://www.kaggle.com/)
   - VÃ¡ em "Account" > "API" > "Create New API Token"
   - O navegador irÃ¡ baixar automaticamente o arquivo `kaggle.json`
   - Crie a pasta `.kaggle` no seu diretÃ³rio home, se ela nÃ£o existir:
     ```bash
     mkdir %USERPROFILE%\.kaggle
     ```
   - Mova o arquivo `kaggle.json` baixado para a pasta `.kaggle`:
     ```bash
     move %USERPROFILE%\Downloads\kaggle.json %USERPROFILE%\.kaggle\
     ```
   - **Importante**: 
     - Nunca compartilhe o arquivo `kaggle.json` ou adicione-o ao controle de versÃ£o
     - O arquivo deve ficar apenas em `%USERPROFILE%\.kaggle\kaggle.json`
     - NÃ£o coloque o arquivo em nenhum outro local do projeto

## ConfiguraÃ§Ã£o das VariÃ¡veis de Ambiente

O projeto utiliza um arquivo `.env` para configurar variÃ¡veis de ambiente importantes. Copie o arquivo `.env.example` para `.env` e configure as seguintes variÃ¡veis:

### SPARK_HOME
- **O que Ã©**: Caminho para a instalaÃ§Ã£o do Apache Spark
- **Como configurar**: 
  1. Baixe o Apache Spark da [pÃ¡gina oficial](https://spark.apache.org/downloads.html)
  2. Descompacte em um diretÃ³rio (ex: `C:/spark-3.5.0-bin-hadoop3`)
  3. Defina `SPARK_HOME` com o caminho completo para este diretÃ³rio

### KAGGLE_USERNAME e KAGGLE_KEY
- **O que Ã©**: Suas credenciais do Kaggle
- **Como configurar**:
  1. Acesse [kaggle.com/account](https://www.kaggle.com/account)
  2. Role atÃ© a seÃ§Ã£o "API"
  3. Clique em "Create New API Token"
  4. Abra o arquivo `kaggle.json` baixado
  5. Copie o valor de "username" para `KAGGLE_USERNAME`
  6. Copie o valor de "key" para `KAGGLE_KEY`

### JAVA_HOME
- **O que Ã©**: Caminho para a instalaÃ§Ã£o do Java JDK
- **Como configurar**:
  1. Instale o Java JDK 11 ou superior
  2. Encontre o diretÃ³rio de instalaÃ§Ã£o (geralmente em `C:/Program Files/Java/jdk-11.x.x`)
  3. Defina `JAVA_HOME` com o caminho completo para este diretÃ³rio

### DATA_PATH
- **O que Ã©**: Caminho para o diretÃ³rio onde os dados serÃ£o armazenados
- **Valor padrÃ£o**: `./data`
- **Como configurar**: 
  - Mantenha o valor padrÃ£o `./data` para usar o diretÃ³rio local
  - Ou defina um caminho absoluto para armazenar os dados em outro local

### KAGGLE_DATASET
- **O que Ã©**: Identificador do dataset do Kaggle que serÃ¡ usado
- **Valor padrÃ£o**: `matheusfreitag/gas-prices-in-brazil`
- **ObservaÃ§Ã£o**: NÃ£o altere este valor, ele Ã© especÃ­fico para este projeto

## Estrutura do Projeto


O projeto segue uma arquitetura em camadas para processamento de dados:
- **Bronze**: Dados brutos extraÃ­dos do Kaggle
- **Silver**: Dados limpos e transformados
- **Gold**: Dados agregados e prontos para anÃ¡lise

```
.
â”œâ”€â”€ data/                      # Dados organizados em camadas
â”‚   â”œâ”€â”€ bronze/               # Dados brutos do Kaggle
â”‚   â”‚   â””â”€â”€ gas_prices_in_brazil/
â”‚   â”œâ”€â”€ silver/              # Modelo Star Schema
â”‚   â”‚   â””â”€â”€ gas_prices_in_brazil/
â”‚   â”‚       â”œâ”€â”€ dim_regiao.parquet
â”‚   â”‚       â”œâ”€â”€ dim_estado.parquet
â”‚   â”‚       â”œâ”€â”€ dim_produto.parquet
â”‚   â”‚       â”œâ”€â”€ dim_tempo.parquet
â”‚   â”‚       â””â”€â”€ fact_precos.parquet
â”‚   â””â”€â”€ gold/                # VisualizaÃ§Ãµes e anÃ¡lises
â”‚       â””â”€â”€ gas_prices_in_brazil/
â”œâ”€â”€ src/                      # CÃ³digo fonte
â”‚   â”œâ”€â”€ infrastructure/      # Componentes compartilhados
â”‚   â”‚   â”œâ”€â”€ data_lake_manager.py
â”‚   â”‚   â””â”€â”€ spark_manager_v2.py
â”‚   â””â”€â”€ pipeline/
â”‚       â””â”€â”€ gas_prices_in_brazil/          # Pipeline especÃ­fico Kaggle
â”‚           â”œâ”€â”€ upstream/    # ExtraÃ§Ã£o (E)
â”‚           â”œâ”€â”€ midstream/   # TransformaÃ§Ã£o (T)
â”‚           â”œâ”€â”€ downstream/  # Load (L)
â”‚           â”œâ”€â”€ etl_pipeline.py
â”‚           â””â”€â”€ run_pipeline.py
â””â”€â”€ tests/                    # Testes automatizados
    â”œâ”€â”€ test_extract.py
    â””â”€â”€ test_reorganized_pipeline.py
```

## Modelo de Dados

### Star Schema (Silver)
- **Fact_Precos**: PreÃ§os dos combustÃ­veis
- **Dim_Regiao**: RegiÃµes do Brasil
- **Dim_Estado**: Estados brasileiros
- **Dim_Produto**: Tipos de combustÃ­vel
- **Dim_Tempo**: DimensÃ£o temporal

## Notas de ImplementaÃ§Ã£o

### Camadas de Dados
- **Bronze**: Dados brutos do Kaggle
- **Silver**: Modelo dimensional otimizado
- **Gold**: VisualizaÃ§Ãµes e anÃ¡lises prontas

### Spark SQL
- Dados em Silver salvos em Parquet
- Otimizado para consultas analÃ­ticas
- Suporte a joins eficientes

### Qualidade de Dados
- ValidaÃ§Ãµes na extraÃ§Ã£o
- TransformaÃ§Ãµes documentadas
- Testes automatizados

## ExecuÃ§Ã£o do Pipeline

### Pipeline Completo
```bash
python src/pipeline/gas_prices_in_brazil/run_pipeline.py
```

### ExecuÃ§Ã£o por Etapas
```bash
# ExtraÃ§Ã£o (Bronze)
python src/pipeline/gas_prices_in_brazil/run_stages.py --stage extract

# TransformaÃ§Ã£o (Silver)
python src/pipeline/gas_prices_in_brazil/run_stages.py --stage transform

# Carregamento (Gold)
python src/pipeline/gas_prices_in_brazil/run_stages.py --stage load
```

## Testes

### Executar Todos os Testes
```bash
python -m pytest tests/
```

### Executar Testes EspecÃ­ficos
```bash
# Teste de extraÃ§Ã£o
python -m pytest tests/test_extract.py

# Teste do pipeline reorganizado
python -m pytest tests/test_reorganized_pipeline.py
```

## Estrutura dos Dados

### Camada Bronze
- Dataset: `gas_prices_in_brazil`
- Arquivo: `2004-2021.tsv`
- Fonte: [Kaggle - Gas Prices in Brazil](https://www.kaggle.com/matheusfreitag/gas-prices-in-brazil)

## Contribuindo

1. Crie um branch para sua feature:
```bash
git checkout -b feature/nova-funcionalidade
```

2. FaÃ§a suas alteraÃ§Ãµes e commit:
```bash
git add .
git commit -m "feat: descriÃ§Ã£o da sua funcionalidade"
```

3. Push para o repositÃ³rio:
```bash
git push origin feature/nova-funcionalidade
```

4. Abra um Pull Request

## ğŸ“ Estrutura do Projeto Organizada

O projeto foi reorganizado seguindo as melhores prÃ¡ticas de engenharia de dados:

- **`src/`** - CÃ³digo fonte principal
  - `upstream/` - MÃ³dulos de extraÃ§Ã£o de dados (ingestÃ£o)
  - `midstream/` - TransformaÃ§Ãµes Bronze â†’ Silver (processamento)
  - `downstream/` - MÃ³dulos de carregamento e entrega
  - `pipeline/` - OrquestraÃ§Ã£o e coordenaÃ§Ã£o do pipeline ETL
  - `infrastructure/` - Gerenciamento de infraestrutura (DataLake, Spark)
  - `analysis/` - AnÃ¡lises e consultas avanÃ§adas
