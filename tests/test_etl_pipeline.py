"""
Script de teste para verificar o pipeline ETL reorganizado
Testa apenas a etapa de transformaÃ§Ã£o com dados existentes
"""

import sys
from pathlib import Path
import logging

# Adicionar caminho raiz do projeto
project_root = Path(__file__).resolve().parent.parent
sys.path.append(str(project_root))

# Configurar logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(name)s] %(levelname)s: %(message)s')

from src.pipeline.kaggle.etl_pipeline import FuelPriceETL, PipelineStage

def test_reorganized_pipeline():
    """Testa o pipeline ETL reorganizado"""
    
    print("="*70)
    print("ğŸ§ª TESTE DO PIPELINE ETL REORGANIZADO")
    print("="*70)
    
    try:
        # Inicializar pipeline
        print("\nğŸ“‹ Inicializando pipeline...")
        etl = FuelPriceETL()
        
        # Encontrar arquivo Bronze mais recente para teste
        bronze_path = project_root / "data" / "bronze" / "kaggle" / "gas_prices_in_brazil"
        
        latest_bronze = None
        if bronze_path.exists():
            for date_dir in sorted(bronze_path.iterdir(), reverse=True):
                if date_dir.is_dir():
                    tsv_file = date_dir / "2004-2021.tsv"
                    if tsv_file.exists():
                        latest_bronze = tsv_file
                        break
          # Verificar se temos dados para testar
        assert latest_bronze is not None, "âŒ Nenhum arquivo Bronze encontrado para teste"
            
        print(f"ğŸ“‚ Usando arquivo Bronze: {latest_bronze}")
        
        # Testar apenas transformaÃ§Ã£o (dados jÃ¡ extraÃ­dos)
        print("\nğŸ”„ Testando etapa de transformaÃ§Ã£o...")
        result = etl.transform(input_file=latest_bronze)
        
        # Verificar resultado
        if result and result.get('success', False):
            print("\nâœ… TESTE CONCLUÃDO COM SUCESSO!")
            
            # Verificar estrutura Silver criada
            silver_path = project_root / "data" / "silver" / "kaggle" / "gas_prices_in_brazil"
            
            print(f"\nğŸ“Š Verificando estrutura Silver em: {silver_path}")
            
            expected_files = [
                "dim_regiao.parquet",
                "dim_estado.parquet", 
                "dim_produto.parquet",
                "dim_tempo.parquet",
                "fact_precos.parquet"
            ]
            
            for file_name in expected_files:
                file_path = silver_path / file_name
                if file_path.exists():
                    size_mb = file_path.stat().st_size / (1024 * 1024)
                    print(f"   âœ… {file_name} ({size_mb:.2f} MB)")
                else:
                    print(f"   âŒ {file_name} - AUSENTE")
            
            return True
        else:
            print("âŒ TESTE FALHOU!")
            print(f"Erro: {result.get('error', 'Erro desconhecido') if result else 'Resultado vazio'}")
            return False
            
    except Exception as e:
        print(f"âŒ ERRO NO TESTE: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def verify_star_schema_structure():
    """Verifica se a estrutura star schema estÃ¡ correta"""
    
    print("\n" + "="*70)
    print("ğŸ” VERIFICAÃ‡ÃƒO DA ESTRUTURA STAR SCHEMA")
    print("="*70)
    
    silver_path = project_root / "data" / "silver" / "kaggle" / "gas_prices_in_brazil"
    
    if not silver_path.exists():
        print("âŒ DiretÃ³rio Silver nÃ£o encontrado!")
        return False
    
    try:
        import pandas as pd
        
        # Verificar cada dimensÃ£o e tabela fato
        tables = {
            "dim_regiao.parquet": "DimensÃ£o de RegiÃµes",
            "dim_estado.parquet": "DimensÃ£o de Estados",
            "dim_produto.parquet": "DimensÃ£o de Produtos",
            "dim_tempo.parquet": "DimensÃ£o de Tempo",
            "fact_precos.parquet": "Tabela Fato de PreÃ§os"
        }
        
        total_size = 0
        
        for file_name, description in tables.items():
            file_path = silver_path / file_name
            
            if file_path.exists():
                df = pd.read_parquet(file_path)
                size_mb = file_path.stat().st_size / (1024 * 1024)
                total_size += size_mb
                
                print(f"âœ… {description}")
                print(f"   ğŸ“ {file_name}")
                print(f"   ğŸ“Š Registros: {len(df):,}")
                print(f"   ğŸ’¾ Tamanho: {size_mb:.2f} MB")
                print(f"   ğŸ”§ Colunas: {list(df.columns)}")
                print()
            else:
                print(f"âŒ {description} - AUSENTE")
                print(f"   ğŸ“ {file_name}")
                print()
          print(f"ğŸ“ˆ TOTAL: {total_size:.2f} MB em estrutura star schema")
        print("ğŸ¯ Estrutura otimizada para queries Spark SQL!")
        
    except Exception as e:
        print(f"âŒ Erro na verificaÃ§Ã£o: {str(e)}")
        raise

if __name__ == "__main__":
    print("ğŸš€ Iniciando testes do pipeline ETL reorganizado...")
    
    # Testar pipeline
    pipeline_ok = test_reorganized_pipeline()
    
    # Verificar estrutura
    structure_ok = verify_star_schema_structure()
    
    print("\n" + "="*70)
    print("ğŸ“‹ RESULTADO FINAL DOS TESTES")
    print("="*70)
    print(f"Pipeline ETL: {'âœ… OK' if pipeline_ok else 'âŒ FALHOU'}")
    print(f"Star Schema: {'âœ… OK' if structure_ok else 'âŒ FALHOU'}")
    
    if pipeline_ok and structure_ok:
        print("\nğŸ‰ REORGANIZAÃ‡ÃƒO CONCLUÃDA COM SUCESSO!")
        print("   â€¢ Pipeline upstream/midstream/downstream funcionando")
        print("   â€¢ Estrutura Silver otimizada para Spark SQL")
        print("   â€¢ Dados em formato Parquet apenas")
        print("   â€¢ Star schema multidimensional implementado")
    else:
        print("\nâš ï¸ PROBLEMAS DETECTADOS - Verifique logs acima")
